
from youtube_summarizer.get_chain import get_time_encoded_transcripts, get_documents, get_summary_with_keywords, get_summary_of_each_video

open_ai_model = "gpt-3.5-turbo"
transcripts = None

'''
def test_long_tail_summarization():

    documents =
    keywords =
    per_document_template =
    combine_document_template =
'''

# 2
# get_time_encoded_transcripts
# save couple of actual transcripts in tests data folder
# compare the actual output with the output returned

# 3
# get documents

# 1
# get_summary_with_keywords
# data a very long transcript, to check long summarization
# I can't exact word by word summaries coz llms change

# 2
# divide_big_summary_into_parts
# check the number of summaries created
# and can do actual compare of returned summaries?

# 1
# get_summary_of_each_video
# don't know how to data this